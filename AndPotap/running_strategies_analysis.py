# ===========================================================================
# Notes
# ===========================================================================
"""
(*) This script outputs the clusters in the running strategies observed
    in the data
"""
# ===========================================================================
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ===========================================================================
# Imports
# ===========================================================================
import os
import numpy as np
import pandas as pd
from AndPotap.Utils.k_means import k_means_lloyds_map
# ===========================================================================
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ===========================================================================
# Files
# ===========================================================================
os.chdir('/Users/andpotap/Documents/Columbia/EDAV/EDAV/AndPotap')
file_data = './DBs/marathon_2018.csv'
file_input = './DBs/marathon_2018_aug.csv'
file_output = './DBs/marathon_2018_clusters.csv'
# ===========================================================================
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Load the data
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# df_all = pd.read_csv(file_input, nrows=100)  # Read a chunk
df_all = pd.read_csv(file_input)  # Read all
# ===========================================================================
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ===========================================================================
# Get the matrix to feed into k-means
# ===========================================================================
selected_columns = [
    'bib',
    'variable',
    'pace'
]
df = df_all[selected_columns].copy()
df.loc[:, 'wNA'] = 1
df.loc[df['pace'].notna(), 'wNA'] = 0
df_na = df.groupby(by='bib').agg({'wNA': np.sum})
df_na = df_na.reset_index()
pivot = df.pivot(index='bib', columns='variable', values='pace')
pivot = pivot.reset_index()
df_output = pivot.copy()
pivot = pivot[pivot.columns.difference(['bib', 'variable'])]
print(f'\nThe number of rows {pivot.shape[0]}, columns {pivot.shape[1]}')
pivot = pivot.dropna()
print(f'\nAfter filtering rows {pivot.shape[0]}, columns {pivot.shape[1]}')
x = pivot.values
# ===========================================================================
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ===========================================================================
# Run k-means
# ===========================================================================
np.random.seed(seed=42)
k = 4
c_0 = np.random.uniform(low=-10, high=10, size=[k, x.shape[1]])
z, c = k_means_lloyds_map(c_0=c_0, x=x)
# ===========================================================================
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ===========================================================================
# Append the clusters
# ===========================================================================
df_output.loc[df_na['wNA'] == 0, 'cluster'] = z
df_output = df_output[['bib', 'cluster']]
data = pd.read_csv(file_data)
data = pd.merge(left=data,
                right=df_output,
                how='inner',
                on='bib')
# ===========================================================================
# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ===========================================================================
# Save the final output
# ===========================================================================
data.to_csv(file_output, index=False)
# ===========================================================================
